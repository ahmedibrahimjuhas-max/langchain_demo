{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/langchain-13-min/blob/main/notebooks/langchain-13-min.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load environment variables\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "env_path = \"\"\n",
        "load_dotenv(env_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY loaded: True\n"
          ]
        }
      ],
      "source": [
        "print(\"OPENAI_API_KEY loaded:\", bool(os.getenv('OPENAI_API_KEY')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/notebooks'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv==1.0.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: langchain==0.0.137 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.0.137)\n",
            "Requirement already satisfied: pinecone-client==2.2.1 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (1.4.54)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (3.13.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (0.5.14)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (1.10.26)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (2.32.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from langchain==0.0.137->-r requirements.txt (line 2)) (8.5.0)\n",
            "Requirement already satisfied: loguru>=0.5.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from pinecone-client==2.2.1->-r requirements.txt (line 3)) (0.7.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from pinecone-client==2.2.1->-r requirements.txt (line 3)) (4.15.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from pinecone-client==2.2.1->-r requirements.txt (line 3)) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from pinecone-client==2.2.1->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from pinecone-client==2.2.1->-r requirements.txt (line 3)) (2.6.3)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from pinecone-client==2.2.1->-r requirements.txt (line 3)) (4.67.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.137->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.137->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.137->-r requirements.txt (line 2)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.137->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.137->-r requirements.txt (line 2)) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.137->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.137->-r requirements.txt (line 2)) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.137->-r requirements.txt (line 2)) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.137->-r requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.137->-r requirements.txt (line 2)) (26.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.137->-r requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.137->-r requirements.txt (line 2)) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.137->-r requirements.txt (line 2)) (2026.1.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.137->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/lib/python3.9/site-packages (from python-dateutil>=2.5.3->pinecone-client==2.2.1->-r requirements.txt (line 3)) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Large language models are advanced artificial intelligence systems designed to understand and generate human language by processing vast amounts of text data and learning patterns, context, and semantics.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "response = llm.invoke(\"Explain large language models in one sentence.\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JtHgQ5XpJmgi"
      },
      "outputs": [],
      "source": [
        "# # import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
        "\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yrfYfKfdJyyF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/72/nxfcp8kj65bbt3qtv2krff1w0000gn/T/ipykernel_92554/552910689.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
            "/var/folders/72/nxfcp8kj65bbt3qtv2krff1w0000gn/T/ipykernel_92554/552910689.py:6: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response=chat(messages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is an example Python script that trains a simple neural network on simulated data using the TensorFlow library:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "import tensorflow as tf\n",
            "\n",
            "# Generate simulated data\n",
            "np.random.seed(0)\n",
            "X = np.random.rand(100, 2)\n",
            "y = np.random.randint(0, 2, 100)\n",
            "\n",
            "# Define the neural network architecture\n",
            "model = tf.keras.Sequential([\n",
            "    tf.keras.layers.Dense(64, activation='relu', input_shape=(2,)),\n",
            "    tf.keras.layers.Dense(64, activation='relu'),\n",
            "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
            "])\n",
            "\n",
            "# Compile the model\n",
            "model.compile(optimizer='adam',\n",
            "              loss='binary_crossentropy',\n",
            "              metrics=['accuracy'])\n",
            "\n",
            "# Train the model\n",
            "model.fit(X, y, epochs=10, batch_size=32)\n",
            "\n",
            "# Evaluate the model\n",
            "loss, accuracy = model.evaluate(X, y)\n",
            "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
            "```\n",
            "\n",
            "In this script:\n",
            "1. We generate simulated data with 2 features and binary labels.\n",
            "2. We define a neural network with 2 hidden layers and an output layer with sigmoid activation.\n",
            "3. We compile the model with binary crossentropy loss and Adam optimizer.\n",
            "4. We train the model on the simulated data for 10 epochs.\n",
            "5. We evaluate the model on the same data and print the loss and accuracy.\n",
            "\n",
            "You can run this script in a Python environment with TensorFlow installed to train a neural network on simulated data.\n"
          ]
        }
      ],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert data scientist\"),\n",
        "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
        "]\n",
        "response=chat(messages)\n",
        "\n",
        "print(response.content,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An autoencoder is a type of artificial neural network used for unsupervised learning, designed to learn efficient representations of data through a process of encoding and decoding. It consists of two main components: an encoder that compresses the input data into a lower-dimensional latent space, and a decoder that reconstructs the original data from this compressed representation, enabling tasks such as dimensionality reduction, feature extraction, and anomaly detection.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "template = \"\"\"\n",
        "You are an expert data scientist with an expertise in building deep learning models. \n",
        "Explain the concept of {concept} in a couple of lines.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "formatted_prompt = prompt.format(concept=\"autoencoder\")\n",
        "\n",
        "response = llm.invoke(formatted_prompt)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dm78i-rUKXIB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/72/nxfcp8kj65bbt3qtv2krff1w0000gn/T/ipykernel_92554/2142282310.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n",
            "/var/folders/72/nxfcp8kj65bbt3qtv2krff1w0000gn/T/ipykernel_92554/2142282310.py:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(chain.run(\"autoencoder\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An autoencoder is a type of artificial neural network used for unsupervised learning that aims to encode input data into a compressed representation and then decode it back to reconstruct the original input. It consists of an encoder that compresses the data into a latent space and a decoder that reconstructs the output from this representation, making it useful for tasks like dimensionality reduction, denoising, and anomaly detection.\n"
          ]
        }
      ],
      "source": [
        "# Import LLMChain and define chain with language model and prompt as arguments.\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An autoencoder is a type of neural network designed to learn efficient representations of data by compressing the input into a lower-dimensional latent space (encoder) and then reconstructing the original input from this representation (decoder). It is primarily used for tasks such as dimensionality reduction, anomaly detection, and data denoising.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "template = \"\"\"\n",
        "You are an expert data scientist with an expertise in building deep learning models. \n",
        "Explain the concept of {concept} in a couple of lines.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "response = chain.invoke({\"concept\": \"autoencoder\"})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alright! Imagine you have a big box of toys. You love playing with all your toys, but keeping them all out can be really messy. So, you decide to put some of them in a smaller box that can hold only a few toys at a time. This smaller box helps you keep your room tidy while still allowing you to play.\n",
            "\n",
            "Now, let’s say you want to remember how to play with all your toys, but you're worried you might forget some of them when they’re in the smaller box. To help with this, you decide to make a special drawing of how each toy looks and how they fit together. You make sure to remember the special things about each toy even though they’re not all out at the same time.\n",
            "\n",
            "In our fun example, the big box of toys is like the original data, which is everything you start with—lots of information! The smaller box is like the “latent space,” the tidier, smaller area where we keep only the most important things about our toys. And your drawing is similar to how we try to remember what each toy looks like while it is in the small box. \n",
            "\n",
            "Now, let’s say you want to show your friend how to play with your toys. You take the drawing you made to explain how your toys fit together and what they do. Your friend might not know exactly how each toy looks from just the drawing, but with the drawing, they can understand your toys well enough to play with them, almost like they are real again! This way, even if the toys are packed away, your friend can still have fun and use their imagination!\n",
            "\n",
            "In this way, the special mechanism you used to pack your toys and then draw them out is like how an autoencoder works! An autoencoder is a kind of computer brain that learns how to shrink down lots of information into a simpler and smaller version, just like you put your toys in the smaller box. \n",
            "\n",
            "There are two important parts to our autoencoder, just like your packing and drawing. The first part is called the “encoder.” This is like the part that puts your toys into the smaller box. The encoder takes all the original information and figures out the most important bits, packing them away neatly. \n",
            "\n",
            "The second part is called the “decoder.” This is like your special drawing; it helps bring back and recreate the toys from the small box. The decoder looks at the important things you remembered and tries to make the toys just like they were before! \n",
            "\n",
            "Sometimes, the drawing isn’t perfect. Maybe it misses a detail or two, but it’s still really helpful! The autoencoder tries to be as perfect as possible at rebuilding the original data from the compressed version, just like how you want your drawing to remind you exactly how to play with all your toys.\n",
            "\n",
            "So, in summary, an autoencoder is like your clever way to keep your toys organized and remember how to play with them. It helps computers understand and remember lots of information without getting too messy, making learning and playing much easier and fun!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "parser = StrOutputParser()\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=\"\"\"\n",
        "You are an expert data scientist with an expertise in building deep learning models. \n",
        "Explain the concept of {concept} in a couple of lines.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\"],\n",
        "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words.\"\n",
        ")\n",
        "\n",
        "chain1 = prompt1 | llm | parser                 # returns a STRING\n",
        "overall_chain = chain1 | (lambda text: {\"ml_concept\": text}) | prompt2 | llm | parser\n",
        "\n",
        "explanation = overall_chain.invoke({\"concept\": \"autoencoder\"})\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a few toys at a time. This smaller box helps you keep your room tidy while still allowing you to\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([explanation])\n",
        "print(texts[2].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z5sv4e3tLw2y"
      },
      "outputs": [],
      "source": [
        "# # Import and instantiate OpenAI embeddings\n",
        "\n",
        "# from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# embeddings = OpenAIEmbeddings(model_name=\"ada\")\n",
        "\n",
        "#Updated import statement for OpenAIEmbeddings\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dqzoir4hMlfl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.03703165054321289, -0.0009642196819186211, -0.03607708215713501, 0.027008678764104843, 0.02240428887307644, -0.051771316677331924, 0.027289435267448425, -0.004046388901770115, -0.010338821448385715, 0.022993875667452812, 0.05424196273088455, -0.017182236537337303, -0.0025794412940740585, -0.011237239465117455, 0.029086269438266754, -0.04143951088190079, -0.01608728989958763, -0.03529096767306328, 0.006271376274526119, 0.01907733641564846, 0.02199719287455082, 0.026812151074409485, 0.027724606916308403, 0.010647652670741081, 0.031781524419784546, 0.008710439316928387, 0.007896248251199722, 0.03770546242594719, 0.06625829637050629, 0.032286882400512695, 0.023990558460354805, -0.021295305341482162, -0.003411179408431053, -0.004092011600732803, 0.013511358760297298, 0.021000511944293976, -0.03523481637239456, -0.008113834075629711, 0.03658244386315346, -0.03397141769528389, -0.013588566333055496, -0.014051812700927258, 0.011784711852669716, 0.00836651399731636, 0.0022337608970701694, 0.06238387152552605, -0.04733537882566452, -0.011960184201598167, -0.03703165054321289, 0.022825421765446663, -0.005629147868603468, 0.05651608482003212, -0.021674325689673424, 0.03891271352767944, 0.02135145664215088, 0.002788253128528595, -0.04879530519247055, 0.035038288682699203, 0.0019828358199447393, 0.03655436635017395, -0.017757786437869072, 0.000614591350313276, 0.021309342235326767, 0.026545433327555656, 0.02488897554576397, -0.02771056815981865, -0.0357121005654335, 0.02128126658499241, -0.02077590674161911, 0.005885337479412556, -0.03829504922032356, 0.004678088705986738, -0.031641144305467606, 0.030153140425682068, 0.02699464187026024, 0.02900204434990883, 0.011981241405010223, 0.0268683023750782, -0.02900204434990883, -0.0300969909876585, -0.043882086873054504, 0.003479613456875086, 0.04124298319220543, 0.005664242431521416, -0.03183767572045326, -0.03458907827734947, -0.015427514910697937, -0.03321337699890137, 0.00792432390153408, -0.039389997720718384, -0.010535350069403648, -0.024495918303728104, -0.07844308763742447, 0.014346606098115444, -0.053034715354442596, 0.012648035772144794, 0.0009536913712508976, -0.0075031910091638565, 0.03458907827734947, 0.013890378177165985, 0.012718223966658115, 0.04070954769849777, -0.018136804923415184, -0.020088056102395058, 0.011539051309227943, 0.013272716663777828, 0.003100593574345112, 0.04166411608457565, -0.08338438719511032, -0.01754721812903881, -0.12723839282989502, -0.026573508977890015, -0.010703803971409798, 0.034392550587654114, -0.06165390834212303, -0.01091437041759491, 0.043741706758737564, 0.05045176297426224, 0.03346605598926544, -0.015315212309360504, 0.0083314199000597, -0.023723840713500977, 0.0139395110309124, -0.021267229691147804, -0.02264293096959591, 0.004116577561944723, -0.004565786570310593, -0.021547984331846237, 0.009650970809161663, 0.010500255972146988, 0.011075804941356182, -0.020312661305069923, 0.027738643810153008, -0.014767739921808243, -0.01886676996946335, 0.003976199775934219, -0.016775140538811684, -0.0013616641517728567, -0.0052045052871108055, 0.03930576890707016, 0.03846350312232971, -0.03371873497962952, -0.027584228664636612, -0.018403522670269012, 0.026138337329030037, 0.016845330595970154, 0.02087417244911194, 0.0011519748950377107, 0.0038007276598364115, 0.002500478643923998, 0.0222779493778944, -0.0007681295392103493, -0.045173559337854385, 0.01563808135688305, 0.06423685699701309, -0.048711080104112625, 0.0459035262465477, 0.06827973574399948, 0.010226518847048283, 0.0021811192855238914, -0.0070610009133815765, -0.024439767003059387, -0.05587034672498703, -0.02189892902970314, 0.01140569243580103, 0.023611538112163544, 0.005485260859131813, 0.028637060895562172, -0.02053726464509964, -0.04649311304092407, 0.004811447579413652, 0.010240556672215462, 0.007264548446983099, -0.0486268550157547, 0.0034164434764534235, -0.004688616842031479, -0.022081419825553894, -0.012254977598786354, -0.03767738863825798, 0.0076084742322564125, 0.035375192761421204, 0.01283754501491785, -0.026362942531704903, -0.033606432378292084, 0.0036954444367438555, -0.0005316807073540986, -0.025394335389137268, -0.0486268550157547, -0.0006650395807810128, -0.007783946581184864, -0.00349014182575047, 0.052585504949092865, 0.008731496520340443, 0.05834099277853966, 0.03371873497962952, -0.06025012955069542, 0.008921005763113499, 0.046296581625938416, 0.0026671772357076406, 0.003193593816831708, 0.01740684174001217, 0.0462404303252697, 0.010135273449122906, -0.02352731116116047, -0.022502554580569267, -0.013363962061703205, -0.03880041092634201, 0.03655436635017395, -0.028384381905198097, -0.04817764461040497, -0.004313106648623943, -0.01649438589811325, -0.02043900080025196, 0.0014748437097296119, -0.08040837943553925, -0.031107710674405098, 0.01584864780306816, 0.0045412201434373856, -0.030714651569724083, 0.02713502012193203, 0.01528713759034872, 0.0329887717962265, 0.04219755157828331, -0.015567893162369728, 0.00020760553888976574, -0.010240556672215462, -0.020565340295433998, -0.05438234284520149, 0.026924453675746918, 0.004976391326636076, 0.02417304925620556, 0.03644206374883652, -0.035206738859415054, -0.05991322547197342, -0.005341373383998871, 0.0431801974773407, -0.011854900978505611, 0.0044218990951776505, 0.03545942157506943, -0.005183448549360037, 0.019470393657684326, -0.004302578046917915, 0.00950357411056757, -0.04506125673651695, 0.011616258881986141, -0.02720520831644535, -0.016817254945635796, -0.019189639016985893, 0.007945381104946136, 0.002121458761394024, 0.034532926976680756, 0.0024425729643553495, 0.00442891800776124, 0.007404926232993603, -0.015694232657551765, -0.03461715206503868, 0.006548622157424688, 0.02156202308833599, 0.02175855077803135, 0.029030120000243187, -0.02020035870373249, 0.005485260859131813, -0.038098521530628204, -0.05471924692392349, -0.0023232516832649708, 0.0397830531001091, 0.04851455241441727, -0.01781393587589264, -0.005608091130852699, 0.01635400764644146, -0.005264165811240673, -0.022081419825553894, 0.010865237563848495, -0.0173366516828537, -0.0028654609341174364, 0.0006505631608888507, 0.04879530519247055, -0.026292752474546432, -0.017252426594495773, -0.0034690850879997015, 0.008394589647650719, -0.010984559543430805, 0.030995408073067665, -0.0023232516832649708, 0.013848265632987022, 0.00860515609383583, -0.016003062948584557, 0.0339994914829731, -0.0024987240321934223, 0.02598392218351364, -0.009819423779845238, -0.03318529948592186, -0.027120981365442276, -0.004832504317164421, -0.027836907655000687, 0.004081482999026775, -0.07675855606794357, -0.01400969922542572, -0.0120724868029356, 0.005737940780818462, 0.025955846533179283, 0.026461206376552582, 0.06990811973810196, 0.016480349004268646, 0.005165901500731707, -0.007959418930113316, -0.011756637133657932, -0.004611409269273281, 0.02285349741578102, 0.02288157306611538, 0.014627361670136452, -0.05429811403155327, 0.04315211996436119, -0.0394461490213871, -0.043264422565698624, -0.03512251377105713, -0.02947932854294777, 0.0033936321269720793, 0.08574273437261581, -0.03955845162272453, -0.04542624205350876, -0.03512251377105713, 0.02852476015686989, -0.017126085236668587, 0.0268683023750782, 0.040372639894485474, 0.0012186543317511678, 0.01490811724215746, -0.018586013466119766, -0.014501022174954414, -0.002802290953695774, 0.03192190080881119, -0.017898162826895714, 0.016438234597444534, 0.015202910639345646, -0.06945890933275223, 0.03223073109984398, -0.01740684174001217, 0.011567126959562302, -0.0007852380513213575, 0.043067894876003265, 0.015427514910697937, -0.009033308364450932, 0.017996428534388542, -0.0181929562240839, 0.053680453449487686, 0.04132721200585365, 0.05137825757265091, -0.014753702096641064, -0.011089842766523361, 0.033101074397563934, -0.03610515967011452, -0.009580781683325768, 6.772129563614726e-05, 0.009257912635803223, -0.0004356097197160125, 0.035515572875738144, -0.021772589534521103, -0.004583333618938923, 0.040849924087524414, 0.004246427211910486, 0.04848647490143776, 0.01979326270520687, 0.006692509166896343, -0.023850180208683014, 0.006320508196949959, -0.05213629826903343, -0.019680960103869438, -0.008527948521077633, 0.04040071740746498, 0.04264676198363304, 0.01764548383653164, 0.035178665071725845, -0.032258808612823486, 0.0009194742888212204, 0.009686064906418324, 0.0710872933268547, 0.01327973511070013, 0.019021185114979744, -0.012507657520473003, 0.020621491596102715, 0.02713502012193203, 0.022741196677088737, -0.021716438233852386, 0.012879658490419388, 0.026854263618588448, -0.018038541078567505, 0.02094436064362526, -0.021983155980706215, -0.055000003427267075, 0.0016336460830643773, -0.03371873497962952, 0.017996428534388542, 0.04424706846475601, -0.026011997833848, -0.010907351039350033, 0.027359623461961746, 0.036161307245492935, -0.016368046402931213, 0.007629530970007181, 0.004239408299326897, 0.0026443658862262964, -0.0283984187990427, 0.011700485832989216, -0.014501022174954414, 0.04989025369286537, 0.0401199609041214, -0.011075804941356182, 0.015160797163844109, -0.0615416057407856, 0.02615237608551979, 0.0256750900298357, 0.0448928065598011, 0.02373787760734558, 0.03882848471403122, -0.023541349917650223, -0.05766718089580536, -0.02713502012193203, -0.005067636724561453, 0.00151520234066993, -0.016059214249253273, -0.025731241330504417, 0.018880806863307953, -0.004755296278744936, -0.0024004594888538122, 0.03402756527066231, -0.03416794538497925, -0.027008678764104843, -0.03329760208725929, -0.031500767916440964, -0.0006216102046892047, 0.003909520339220762, -0.00814190972596407, -0.029675856232643127, 0.023583462461829185, 0.0006970632821321487, -0.03989535570144653, -0.0009817668469622731, -0.0062257531099021435, -0.06625829637050629, 0.03753701224923134, -0.018894845619797707, 0.013251659460365772, 0.07322103530168533, -0.043573252856731415, 0.008633231744170189, -0.019203675910830498, 0.006239790935069323, 0.0006707424181513488, 0.04009188711643219, -0.0049307686276733875, -0.017631445080041885, -0.04907606169581413, 0.056628383696079254, -0.030068915337324142, 0.022979838773608208, 0.016648801043629646, 0.024032671004533768, 0.024355540052056313, 0.014192190952599049, 0.05222052335739136, 0.020116131752729416, 0.02615237608551979, -0.0023723840713500977, 0.04160796478390694, -0.023274632170796394, 0.014206228777766228, 0.019091375172138214, -0.020860133692622185, -0.03720010444521904, -0.014599286019802094, -0.04264676198363304, 0.03621745854616165, 0.07529862970113754, 0.0158065352588892, -0.007320699747651815, 0.007861154153943062, 0.0992751494050026, -0.00289529119618237, -0.037593163549900055, 0.010416029021143913, 0.03722817823290825, -0.05929556116461754, -0.02438361570239067, -0.0039270673878490925, -0.010921388864517212, -0.04660541191697121, 0.02825804241001606, -0.024734560400247574, 0.036133233457803726, -0.07984686642885208, 0.04635273292660713, 0.008240174502134323, -0.017055897042155266, 0.008289306424558163, -0.04859877750277519, 0.008289306424558163, -0.04843032360076904, 0.024425728246569633, 0.026068149134516716, 0.020410925149917603, 0.003126914380118251, 0.0171681996434927, 0.014669475145637989, -0.043882086873054504, 0.02598392218351364, 0.03899693861603737, -0.014627361670136452, -0.01692955754697323, 0.01740684174001217, 0.018993109464645386, -0.020424962043762207, -0.002677705604583025, 0.004302578046917915, 0.022263910621404648, -0.03756508603692055, -0.02424323745071888, 0.015188872814178467, 0.022867536172270775, -0.02615237608551979, -0.002391685964539647, 0.0037656330969184637, 0.02003190480172634, 0.003860388183966279, 0.03189382702112198, 0.005029032938182354, -0.02615237608551979, 0.001861759927123785, 0.017462993040680885, 0.014297474175691605, -0.015666157007217407, -0.022769272327423096, 0.004060426261276007, 0.01874043047428131, 0.009321082383394241, 0.0011730316327884793, -0.0008734128205105662, -0.01591883786022663, 0.0010931917931884527, -0.0035971798934042454, 0.0319499745965004, 0.06434915959835052, 0.03074272722005844, -0.007106623612344265, 0.005850242916494608, -0.0158065352588892, -0.038575805723667145, 0.005320316646248102, 0.02407478541135788, 0.03868810832500458, 0.016368046402931213, -0.016143441200256348, 0.01625574380159378, -0.02505742944777012, 0.016648801043629646, 0.003505934262648225, -0.00861919391900301, 0.003674387698993087, 0.028749363496899605, 0.013953548856079578, -0.013609622605144978, -0.014964268542826176, 0.028749363496899605, 0.03346605598926544, 0.024271313101053238, 0.036975499242544174, 0.03992343321442604, 0.012774375267326832, 0.029703931882977486, -0.01996171660721302, -0.020635530352592468, 0.009812405332922935, 0.010612557642161846, -0.022179685533046722, -0.004144653212279081, 0.020523227751255035, 0.051602862775325775, 0.0008690260001458228, -0.02366768941283226, 0.013834227807819843, -0.025647016242146492, -0.03279224410653114, -0.030518123880028725, -0.0038884638343006372, -0.04626850783824921, 0.014079888351261616, -0.007383869960904121, -0.0027987814974039793, -0.009447422809898853, -0.012928791344165802, -0.013609622605144978, -0.03335375338792801, 0.017462993040680885, 0.030209291726350784, -0.010837162844836712, 0.00720137869939208, -0.033381830900907516, -0.006362621672451496, 0.00043275830103084445, -0.0020038923248648643, -0.011160030961036682, 0.013714906759560108, -0.04618427902460098, -0.04141143709421158, -0.054017357528209686, 0.015188872814178467, -0.01764548383653164, 0.028215928003191948, 0.003891973290592432, 0.03124808706343174, 0.008106815628707409, -0.02400459535419941, -0.007468096446245909, -0.0049202400259673595, -0.03012506477534771, -0.010921388864517212, -0.025520674884319305, 0.028244003653526306, -0.01368683110922575, -0.04138335958123207, -0.01563808135688305, 0.015188872814178467, -0.03868810832500458, -0.011363578960299492, -0.012781394645571709, 0.036470141261816025, 0.020003829151391983, -0.01577845960855484, -0.030405821278691292, 0.01601710170507431, -0.00993172638118267, 0.0075453040190041065, 0.015216948464512825, -0.012690149247646332, -0.061092399060726166, -0.0065626599825918674, -0.002496969187632203, -0.0214216448366642, 0.040513020008802414, 0.06350689381361008, 0.050957124680280685, -0.0031444616615772247, 0.015216948464512825, 0.0022127043921500444, 0.014669475145637989, 0.04416283965110779, -0.019905565306544304, 0.0055308835580945015, 0.012690149247646332, 0.003100593574345112, 0.02584354393184185, -0.0013335886178538203, 0.03492598608136177, -0.011517994105815887, 0.002267100615426898, -0.011658372357487679, -0.009278969839215279, -0.0744563564658165, -0.015343287959694862, 0.008563042618334293, 0.00817700382322073, 0.013413093984127045, 0.007215416524559259, 0.0036989536602050066, -0.006331036798655987, -0.008057682774960995, -0.0027391209732741117, -0.03304492309689522, -0.006432810332626104, -0.020593415945768356, -0.01090033259242773, 0.02175855077803135, -0.0018020994029939175, -0.020691679790616035, -0.000447234750026837, 0.02206738293170929, 0.032904546707868576, 0.006692509166896343, 0.009447422809898853, 0.026362942531704903, 0.01050727441906929, -0.02230602502822876, -0.0020986474119126797, 0.013104262761771679, 0.02340097166597843, -0.03183767572045326, 0.013139357790350914, 0.003727029310539365, -0.01587672345340252, 0.011433768086135387, -0.031472690403461456, -0.00582216726616025, -0.01052131224423647, 0.008942062966525555, 0.013048112392425537, 0.00676620751619339, 0.031332314014434814, -0.05794793739914894, 0.0034164434764534235, -0.039698828011751175, -0.0020056471694260836, 0.002228496829047799, -0.02036881260573864, -0.002147779567167163, -0.03958652541041374, -0.0384354293346405, -0.004513144958764315, 0.041944872587919235, -5.9002522903028876e-05, -0.002130232285708189, -0.035992857068777084, 0.026938490569591522, 0.029591629281640053, 0.042590610682964325, 0.01348328310996294, -0.01329377293586731, 0.009847499430179596, -0.025829507037997246, 0.028033437207341194, -0.025787392631173134, 0.020593415945768356, -0.007131190039217472, -0.04958142340183258, 0.0093491580337286, 0.020551303401589394, -0.024874936789274216, -0.005653713829815388, -0.007099604699760675, -0.014325549826025963, -0.0007856767042540014, 0.013988642953336239, 0.007039944175630808, -0.0084156459197402, -0.023302705958485603, -0.016915518790483475, 0.014486984349787235, -0.02020035870373249, -0.009475498460233212, -0.03916539251804352, -0.017589332535862923, 0.002619799692183733, -0.02247447893023491, 0.006194168236106634, 0.001753844553604722, -0.015750383958220482, -0.030798878520727158, 0.0004439446493051946, -0.013644717633724213, -0.03464522957801819, 0.014557172544300556, -0.028623024001717567, 0.012718223966658115, -0.004035860300064087, 0.007411945145577192, 0.0016880424227565527, -0.05505615472793579, 0.005608091130852699, 0.02818785235285759, 0.02852476015686989, 0.01591883786022663, -0.013700868934392929, -0.0036252555437386036, -0.04407861456274986, 0.0030549708753824234, -0.00950357411056757, -0.011707504279911518, -0.015315212309360504, -0.00816296599805355, 0.020551303401589394, -0.0159749872982502, 0.0005509826587513089, -0.0016748820198699832, 0.028861666098237038, -0.03343798220157623, -0.004249936435371637, -0.013005998916924, 0.043713632971048355, 0.014851965941488743, 0.012247959151864052, -0.02180066518485546, -0.0024829315952956676, 0.022741196677088737, -0.03767738863825798, -0.0363859124481678, -0.0020354774314910173, -0.018950996920466423, 0.05907095968723297, -0.003476104000583291, 0.02046707645058632, -0.04907606169581413, 0.0042008040472865105, -0.047896888107061386, -0.017912201583385468, -0.005871299654245377, -0.03321337699890137, -0.008071720600128174, -0.0153854014351964, -0.03270801529288292, -0.0052466182969510555, 0.021028587594628334, 0.003688425524160266, -0.005029032938182354, -0.008240174502134323, -0.0018389485776424408, 0.02931087464094162, 0.0329887717962265, -0.022025268524885178, -0.024299388751387596, -0.02498723939061165, 0.015230986289680004, 0.0034515380393713713, 0.020045943558216095, 0.019610771909356117, 0.0022688554599881172, 0.0273736622184515, 0.01709800958633423, -0.027177132666110992, -0.009243874810636044, 0.023443084210157394, -0.008345457725226879, 0.015202910639345646, 0.004099030513316393, 0.010626595467329025, -0.00396216195076704, 0.019807301461696625, 0.01217075064778328, -0.03756508603692055, 0.0195546206086874, 0.035038288682699203, -0.004611409269273281, 0.011777693405747414, -0.015006382018327713, -0.05151863396167755, -0.0005558081902563572, 0.028623024001717567, 0.02897396869957447, -0.008710439316928387, -0.011496937833726406, -0.02883359044790268, 0.014866003766655922, -0.07423175871372223, 0.00018808426102623343, -0.028244003653526306, -0.01972307451069355, -0.0161574799567461, 0.028300154954195023, -0.01893695816397667, 0.019049260765314102, -0.0158065352588892, 0.05682491511106491, -0.0003577439347282052, 0.02029862254858017, 0.03753701224923134, 0.006159073673188686, -0.026376979425549507, 0.0052045052871108055, 0.022600818425416946, 0.03346605598926544, -0.008738514967262745, 0.015259061940014362, -0.022979838773608208, 0.06760592758655548, -0.0022372703533619642, -0.012318147346377373, -0.01236026082187891, -0.029395101591944695, 0.052585504949092865, 0.007032925263047218, -0.003163763554766774, 0.019807301461696625, -0.0005369448917917907, -0.007594436407089233, -0.0012660318752750754, 0.029844310134649277, 0.011574145406484604, 0.02928279899060726, -0.020256510004401207, -0.02104262448847294, 0.0047482773661613464, 0.01996171660721302, -0.0134341511875391, 0.05603879690170288, 0.01047218032181263, 0.02713502012193203, -0.0054256003350019455, 0.00029523196280933917, 0.015722308307886124, 0.0041481624357402325, 0.03655436635017395, 0.013785094954073429, -0.005064127501100302, 0.02947932854294777, -0.005144844762980938, -0.004134124610573053, -0.017519144341349602, 0.0227833092212677, 0.01723838783800602, 0.013153395615518093, 0.040990304201841354, 0.02730347216129303, -0.03795814514160156, 3.4079988836310804e-05, -0.0020898738875985146, -0.003437500214204192, -0.04722307622432709, 0.02244640327990055, 0.035852476954460144, -0.006818849127739668, 0.029900461435317993, 0.014557172544300556, -0.004779862239956856, -0.009594819508492947, 0.03369066119194031, -0.009117535315454006, 0.01635400764644146, -0.0033602924086153507, 0.022109495475888252, -0.03063042461872101, 0.012823508121073246, -0.0055308835580945015, -0.026054110378026962, -0.025015315040946007, 0.04236600548028946, -0.029226647689938545, -0.005685299169272184, 0.017519144341349602, -0.014669475145637989, 0.01490811724215746, 0.04843032360076904, -0.011321465484797955, 0.0031251597683876753, -0.008612175472080708, 0.013764038681983948, 0.009398290887475014, 0.01625574380159378, -0.02022843435406685, -0.016704952344298363, -0.0017178726848214865, -0.015862686559557915, -0.040007658302783966, -0.010830143466591835, -0.0006501244497485459, 0.018080653622746468, 0.005225562024861574, 0.04087800160050392, -0.04270291328430176, 0.008184023201465607, 0.02084609679877758, -0.013504339382052422, 0.0035971798934042454, 0.02880551479756832, 0.025169730186462402, 0.015960950404405594, -0.03074272722005844, -0.026671772822737694, 0.012830526567995548, 0.0062362817116081715, 0.008745534345507622, 0.05297856405377388, -0.00652756541967392, -0.010282670147716999, -0.009054364636540413, -0.021435683593153954, 0.027317510917782784, -0.03335375338792801, -0.0024074784014374018, 0.016073253005743027, 0.00509220315143466, 0.030068915337324142, 0.002365365158766508, 0.00020201236475259066, 0.02570316568017006, -0.011714523658156395, 0.0161574799567461, 0.0035936704371124506, 0.02928279899060726, 0.04379785805940628, 0.009475498460233212, 0.010942446067929268, -0.02271312102675438, -0.02859494835138321, 0.033269528299570084, 0.0014265888603404164, -0.019933640956878662, -0.013918453827500343, 0.038716185837984085, 0.0006887283525429666, -0.01601710170507431, 0.007741833105683327, -0.02135145664215088, 0.0130902249366045, 0.00509220315143466, -0.037256255745887756, -0.002147779567167163, 0.017027821391820908, 0.05182746425271034, 0.000713733141310513, 0.023569423705339432, 0.01778586208820343, 0.020453037694096565, -0.043236348778009415, -0.04604390263557434, 0.03666666895151138, 0.011798749677836895, 0.009173685684800148, -0.024608219042420387, 0.028861666098237038, 0.012521695345640182, -0.0557580441236496, 0.01673302799463272, -0.011763655580580235, -0.04506125673651695, 0.028945893049240112, 0.03402756527066231, 0.028608985245227814, 0.007868172600865364, 0.016606688499450684, -0.03349413350224495, -0.03989535570144653, -0.015455590561032295, 0.0012397110695019364, 0.014353625476360321, 0.0312761627137661, 0.03750893473625183, 0.00625733844935894, 0.009559724479913712, -0.0038568787276744843, -0.028608985245227814, 0.01504849549382925, -0.001581881777383387, 0.000614591350313276, 0.004162200260907412, -0.019596735015511513, 0.01642419770359993, 0.05317509174346924, 0.014283436350524426, -0.014683512970805168, -0.055786117911338806, -0.014837928116321564, 0.035010211169719696, -0.028005361557006836, -0.03559979796409607, -0.03958652541041374, 0.04733537882566452, 0.012963885441422462, -0.010549387894570827, 0.00221445900388062, -0.04031648859381676, 0.013202527537941933, -0.004902692977339029, 0.009622895158827305, 0.017083972692489624, -0.0418325699865818, 0.01561000570654869, 0.01883869431912899, -0.011840863153338432, -0.010114217177033424, -0.03821082413196564, 0.015399439260363579, -0.004786881152540445, -0.034364473074674606, -0.003493651282042265, -0.011005615815520287, 0.010584482923150063, -0.019358092918992043, 0.020312661305069923, -0.05123788118362427, -0.023485198616981506, 0.012058448977768421, -0.010135273449122906, 0.005443147383630276, 0.020017867907881737, -0.0029233666136860847, -0.03930576890707016, 0.00047860038466751575, -0.023372896015644073, 0.006843415554612875, -0.03540327027440071, -0.0026320829056203365, 0.013504339382052422, 0.037452783435583115, 0.027584228664636612, -0.02366768941283226, -0.0021916476543992758, -0.03385911509394646, 0.01327973511070013, -0.0064714145846664906, 0.006081866100430489, -0.010542369447648525, -0.016003062948584557, -0.00764356879517436, 0.0166628398001194, 0.013223583810031414, 0.01074591651558876, -0.004327144008129835, 0.010893313214182854, -0.003316424321383238, -0.0064994897693395615, -0.01754721812903881, 0.008556024171411991, 0.016845330595970154, -0.01628381945192814, 0.0013625415740534663, 0.02223583683371544, 0.013230603188276291, -0.011925090104341507, -0.01659264974296093, 0.013750000856816769, 0.0026268186047673225, 0.058846354484558105, -0.013862303458154202, 0.02615237608551979, -0.0024022143334150314, -0.010731878690421581, -0.030546199530363083, 0.00036585950874723494, -0.0023460632655769587, -0.011230220086872578, -0.021786626428365707, 0.021716438233852386, -0.01785605028271675, -0.011517994105815887, 0.0097773103043437, 0.03287646919488907, 0.009770291857421398, -0.006369640585035086, 0.02424323745071888, -0.007931343279778957, 0.01656457409262657, 0.000507114629726857, -0.027092905715107918, -0.019835377112030983, 0.004393823444843292, -0.007327718660235405, -0.0038498598150908947, 0.016480349004268646, -0.0053624301217496395, -0.017224350944161415, -0.019877489656209946, 0.008198061026632786, 0.009580781683325768, -0.012318147346377373, -0.007510209921747446, -0.01208652462810278, -0.027864983305335045, -0.013511358760297298, 0.02730347216129303, 0.08922410011291504, 0.011461843736469746, -0.04346095025539398, -0.005744959693402052, 0.015469628386199474, -0.021632211282849312, -0.011398673057556152, -0.012191807851195335, -0.00038647750625386834, 0.03237111121416092, -0.02139356918632984, 0.008689383044838905, 0.005004466976970434, 0.009770291857421398, 0.022151609882712364, -0.002700516954064369, -0.009510592557489872, -0.018810618668794632, 0.02917049638926983, -0.015694232657551765, 0.041467588394880295, -0.07294028252363205, -0.03832312673330307, -0.03304492309689522, 0.04056917130947113, -0.022502554580569267, 0.0489637590944767, -0.03282031789422035, -0.008991194888949394, 0.03981113061308861, 0.01252871472388506, -0.02281138487160206, -0.030068915337324142, 0.01744895428419113, 0.027149057015776634, -0.017013782635331154, 0.007404926232993603, -0.009419347159564495, -0.018614089116454124, 0.0014257115544751287, 0.010802067816257477, 0.010366897098720074, -0.011693466454744339, 0.0071241711266338825, 0.025955846533179283, 0.022600818425416946, -0.006345074623823166, -0.0200599804520607, 0.0046956357546150684, 0.00953866820782423, -0.0016310140490531921, 0.004555257968604565, -0.003688425524160266, 0.010296707972884178, 0.0065626599825918674, 0.004460502881556749, 0.017491068691015244, -0.012493619695305824, 0.0068785096518695354, 0.04073762521147728, -0.010809087194502354, -0.024397652596235275, -0.008780628442764282, -0.005022014025598764, 0.008205079473555088, 0.010879275389015675, -0.005987111013382673, 0.019358092918992043, 0.04899183660745621, 0.03767738863825798, 0.0030918200500309467, 0.009454441256821156, -0.03559979796409607, -0.03717202693223953, 0.020902248099446297, 0.019666923210024834, 5.61236847715918e-05, -0.010086141526699066, -0.00029150318005122244, 0.010991577990353107, -0.01419920939952135, -0.0060678282752633095, 0.012479581870138645, 0.023681726306676865, -0.04444359615445137, 0.017912201583385468, -0.014107964001595974, 0.017434917390346527, 0.005766015965491533, 0.013406075537204742, -0.014950230717658997, 0.0016599668888375163, 0.005102731287479401, -0.014978306367993355, -0.009384253062307835, -0.00030005743610672653, -0.035038288682699203, -0.00047070413711480796, -0.006488961633294821, -0.0035006701946258545, -0.005618619732558727, 0.006218734197318554, -0.021842777729034424, 0.012507657520473003, 0.017364727333188057, -0.010163349099457264, -0.006064319051802158, 0.022671006619930267, 0.015441552735865116, -0.006081866100430489, 0.0004206945886835456, -0.03442062437534332, -0.0014695796417072415, 0.029591629281640053, 0.0029023101087659597, 0.025562789291143417, 0.005158882588148117, -0.033381830900907516, -0.0009940499439835548, -0.012935809791088104, 0.024903012439608574, -0.008148928172886372, 0.014809852465987206, 0.01723838783800602, 0.0195546206086874, 0.03442062437534332, -0.01489407941699028, -0.005165901500731707, -0.009693083353340626, -0.012261996977031231, 0.003437500214204192, 0.028945893049240112, 0.02410285919904709, -0.003035668982192874, 0.004267483483999968, -0.0008848184952512383, -0.029030120000243187, -0.009868555702269077, 0.0027549134101718664, -0.004986919462680817, 0.004407861270010471, 0.031641144305467606, -0.0003395386738702655, -0.002782988827675581, 0.021000511944293976, -0.001459928578697145, 0.016297856345772743, -0.0316130705177784, -0.0455666184425354, 0.003790199290961027, -0.008549004793167114, 0.0012432204093784094, -0.019203675910830498, -0.030546199530363083, 0.006692509166896343, 0.00948953628540039, 0.023990558460354805, 0.029114345088601112, 0.030686575919389725, -0.021267229691147804, 0.03669474273920059, -0.002704026410356164, 0.0037656330969184637, 0.006864472292363644, 0.013160414062440395, 0.018164880573749542, -0.01601710170507431, -0.02553471364080906, 0.022151609882712364, -0.015497704036533833, -0.010563425719738007, -0.021856816485524178, -0.00814190972596407, -0.00017196274711750448, 0.006285413634032011, 0.0071768127381801605, 0.03107963502407074, -0.006920623127371073, -0.0302654430270195, -0.03832312673330307, 0.038098521530628204, 0.01183384470641613, -0.019021185114979744, 0.03200612589716911, -0.032764166593551636, 0.011981241405010223, 0.010717841796576977, -0.002811064478009939, -0.030040839686989784, -0.012739281170070171, -0.023134253919124603, 0.023302705958485603, -0.014353625476360321, -0.0370597280561924, 0.03380296379327774, -0.011398673057556152, -0.026699848473072052, -0.009847499430179596, -0.012949847616255283, 0.011237239465117455, -3.465575719019398e-05, -0.031472690403461456, -0.005660732742398977, -0.03618938475847244, 0.013995662331581116, -0.04239408299326897, -0.014683512970805168, 0.042759064584970474, 0.02849668450653553, -0.0023197424598038197, 0.03189382702112198, 0.0241449736058712, -0.007622512057423592, 0.008682363666594028, -0.0005299260374158621, -0.018389485776424408, -0.0135183772072196, 0.00809277780354023, -0.043404802680015564, -0.015245024114847183, -0.01327973511070013, -0.01692955754697323, 0.040484942495822906, -0.002286402741447091, -0.03270801529288292, 0.03509443625807762, -0.014964268542826176, -0.0161574799567461, -0.018389485776424408, 0.014030756428837776, 0.030967332422733307, 0.0041481624357402325, -0.018796581774950027, -0.027401737868785858, 0.0055729965679347515, -0.026054110378026962, -0.0027391209732741117, -0.009145610965788364, -0.020663606002926826, -0.0033374810591340065, -0.014304492622613907, 0.02577335573732853, -0.0036147271748632193, -0.03267994150519371, -0.0012774375500157475, 0.01685936748981476, -0.0018600051989778876, -0.017055897042155266, 0.01721031218767166, -0.018922921270132065, 0.01697167009115219, 0.035347118973731995, 0.002884762827306986, -0.012205845676362514, 0.007075038738548756, -0.02689637802541256, 0.004779862239956856, -0.033269528299570084, 0.025408372282981873, 0.0011353050358593464, -0.045987751334905624, 0.022965800017118454, 0.04635273292660713, 0.0033638018649071455, -0.02013017050921917, -0.015202910639345646, -0.048739153891801834, 0.014922155067324638, -0.020832058042287827, -0.0010493237059563398, 0.004155181348323822, 0.016718991100788116, -0.02665773592889309, -0.00394461490213871, 0.01074591651558876, 0.043573252856731415, -0.0015932874521240592, -0.017912201583385468, -0.008022588677704334, -0.024060746654868126, 0.0047482773661613464, 0.008324400521814823, -0.03253956139087677, -0.005769525654613972, 0.013651736080646515, 0.01584864780306816, -0.027177132666110992, 0.009412328712642193, 0.0068258680403232574, -0.002284647896885872, 0.021870853379368782, 0.005562468431890011, -0.020424962043762207, 0.02699464187026024, 0.014143058098852634, 0.013300792314112186, -0.0016152214957401156, -0.02761230431497097, -0.02077590674161911, 0.02386421710252762, 0.031163860112428665, -0.00027636869344860315, -0.008394589647650719, 0.00902628991752863, -0.02166028693318367, 0.021435683593153954, -0.009370215237140656, 0.06238387152552605, -0.014823890291154385, -0.0024109878577291965, -0.015076570212841034, -0.007250511087477207, -0.008520929142832756, -0.028707250952720642, -0.030181216076016426, -0.030181216076016426, -0.05570189282298088, -0.03635783866047859, 0.01568019576370716, 0.032286882400512695, 0.021786626428365707, 0.040793776512145996, 0.0073347375728189945, -0.023513274267315865, -0.0506763681769371, 0.010444104671478271, 0.021211078390479088, -0.02254466712474823, 0.006138017401099205, -0.026405055075883865, 0.010549387894570827, 0.01042304839938879, 0.03214650601148605, 0.0023179876152426004, 0.0004446026578079909, -0.008254211395978928, -0.01110388059169054, 0.02900204434990883, -0.022937724366784096, -0.022320061922073364, 0.006411754060536623, 0.014599286019802094, -0.018108729273080826, 0.04916029050946236, 0.02445380389690399, 0.039867281913757324, 0.048037268221378326, 0.02397651970386505, -0.06277693063020706, 0.005313297733664513, -0.0023197424598038197, 0.03369066119194031, 0.013876340351998806, -0.013413093984127045, -0.0035322553012520075, 0.014557172544300556, 0.014290454797446728, -0.03279224410653114, -0.006913604214787483, -0.0007141717942431569, 0.00013083645899314433, 0.020761869847774506, 0.030855029821395874, 0.006453867070376873, -0.0130902249366045, -0.009966820478439331, -0.00081287493230775, 0.025927770882844925, 0.0181929562240839, -0.06294538080692291, 0.013349924236536026, 0.005295750685036182, 0.014823890291154385, 0.0034918966703116894, -0.05126595497131348, -0.057246048003435135, -0.01876850612461567, -0.003318179165944457, -0.021267229691147804, 0.02022843435406685, 0.013644717633724213, -0.007369832135736942, 0.011012634262442589, 0.006674962118268013, 0.05438234284520149, 0.017533181235194206, 0.0029672347009181976, -0.02438361570239067, 0.004544729832559824]\n",
            "1536\n"
          ]
        }
      ],
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "\n",
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "print(query_result)\n",
        "print(len(query_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PINECONE_API_KEY loaded: True\n"
          ]
        }
      ],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
        "print(\"PINECONE_API_KEY loaded:\", bool(os.getenv('PINECONE_API_KEY')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating indexes in pinecone for the first time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pc.create_index(\n",
        "#     name=\"langchain-quickstart\",\n",
        "#     dimension=1536,\n",
        "#     metric=\"cosine\",\n",
        "#     spec={\n",
        "#         \"serverless\": {\n",
        "#             \"cloud\": \"aws\",\n",
        "#             \"region\": \"us-east-1\"\n",
        "#         }\n",
        "#     }\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lZhSUt3FNBzN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['4df32150-721d-4ce2-9033-8c4f27356897', '3f7564d1-f6f5-4a04-a038-fdf454280a7d', '59bd7cd5-e41f-4efe-97fb-b1449885a87d', '5c845fac-11f7-4f0b-86c0-ded6b0c884d4', '34a787b9-1f9c-4518-97e6-62b799a74029', '90070c8f-b8fa-4baa-abcc-1798455fb4b0', 'ecc6e271-91cf-493a-971c-4aff6d476c20', '41eae807-ce08-4cff-b667-62651f80d7d0', 'd065b941-8b94-4a1c-a9cc-ee0e663949b2', '43215351-cbd6-40f5-b24f-fdadf28bc4ac', '0ecc1da3-9212-4a62-87e8-ee74c74082ad', 'adf53fe1-8a86-40cb-88b6-a46e2b30071e', '3aa4bbd0-c492-4ea5-b115-dd94b8f7b023', 'd777d4ca-cff9-4303-94ad-b5572b9914d0', '9bbcbee1-fc8d-4ba1-a40d-1d340de86070', '45e29b52-baf1-418c-89e4-3a289a5432e2', 'b5f03e8a-50c7-45f0-bd34-4ffaaef77cc1', '38387ba6-1cbf-4edd-a7c9-be23bc0532cb', '7e0f6cc2-39c5-48a1-9d95-f0e537e2f7c9', 'e91190e0-3919-4e9e-8ebb-758a5e394dbc', '8d9d2418-f8bf-47cc-8bd7-e9973deded26', '34dfc02f-0eef-4dc0-9354-133b87a69582', '657e8428-deba-43ca-ab0f-cee3a5809bf3', 'd23ace60-4371-4a57-973e-be2a9b6b5a17', '4561d8eb-0743-4a91-a160-2b4c1523ea1d', 'a200e7d2-6437-477a-89fe-e5a46aed3579', '751dfa33-c696-4538-ba84-0874a7dc9fd4', '8cfceca5-f91a-4521-83ef-203c42d180e5', '44b9ce39-508e-401c-95b4-64843b5edc64', 'df7798f7-e0ae-44c7-b9bc-c0727e4bc2c7', '1822900a-9fd7-4719-81c4-7826f9a304cf', '34653d65-f6c6-4546-b86a-5ae08b80e784', 'cf04845c-ae61-4916-bf88-e08311271432', '714dc038-4a49-491b-8497-2e3e7e590788']\n",
            "Added 34 documents to Pinecone index 'langchain-quickstart'.\n"
          ]
        }
      ],
      "source": [
        "# Upload vectors to Pinecone\n",
        "\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "index_name = \"langchain-quickstart\"\n",
        "# search = Pinecone.from_documents(texts, embeddings, index_name=index_name)\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "index.delete(delete_all=True)\n",
        "\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "\n",
        "\n",
        "\n",
        "ids = vector_store.add_documents(texts)\n",
        "\n",
        "# ids = vector_store.add_documents(texts)\n",
        "print(ids)\n",
        "print(f\"Added {len(ids)} documents to Pinecone index '{index_name}'.\")  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2906"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(texts)\n",
        "len(explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min: 5\n",
            "Max: 99\n",
            "Avg: 84.1470588235294\n",
            "Total chunks: 34\n"
          ]
        }
      ],
      "source": [
        "sizes = [len(doc.page_content) for doc in texts]\n",
        "print(\"Min:\", min(sizes))\n",
        "print(\"Max:\", max(sizes))\n",
        "print(\"Avg:\", sum(sizes)/len(sizes))\n",
        "print(\"Total chunks:\", len(sizes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The second part is called the “decoder.” This is like your special drawing; it helps bring back and\n"
          ]
        }
      ],
      "source": [
        "query = \"What is magical about an autoencoder?\"\n",
        "result = vector_store.similarity_search(query, k = 8)\n",
        "print(result[6].page_content)\n",
        "# print(result[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result 0\n",
            "autoencoder works! An autoencoder is a kind of computer brain that learns how to shrink down lots\n",
            "Length: 97\n",
            "------\n",
            "Result 1\n",
            "So, in summary, an autoencoder is like your clever way to keep your toys organized and remember how\n",
            "Length: 99\n",
            "------\n",
            "Result 2\n",
            "helpful! The autoencoder tries to be as perfect as possible at rebuilding the original data from\n",
            "Length: 96\n",
            "------\n",
            "Result 3\n",
            "There are two important parts to our autoencoder, just like your packing and drawing. The first\n",
            "Length: 95\n",
            "------\n",
            "Result 4\n",
            "encoder takes all the original information and figures out the most important bits, packing them\n",
            "Length: 96\n",
            "------\n",
            "Result 5\n",
            "part is called the “encoder.” This is like the part that puts your toys into the smaller box. The\n",
            "Length: 97\n",
            "------\n",
            "Result 6\n",
            "The second part is called the “decoder.” This is like your special drawing; it helps bring back and\n",
            "Length: 99\n",
            "------\n",
            "Result 7\n",
            "recreate the toys from the small box. The decoder looks at the important things you remembered and\n",
            "Length: 98\n",
            "------\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(result):\n",
        "    print(\"Result\", i)\n",
        "    print(doc.page_content)\n",
        "    print(\"Length:\", len(doc.page_content))\n",
        "    print(\"------\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/72/nxfcp8kj65bbt3qtv2krff1w0000gn/T/ipykernel_92554/3670828019.py:9: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\n# Coefficients of the quadratic equation ax^2 + bx + c\\na = 3\\nb = 2\\nc = -1\\n\\n# Calculate the discriminant\\nD = b**2 - 4*a*c\\n\\n# Calculate the two roots using the quadratic formula\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\n\\nroot1, root2'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\na = 3\\nb = 2\\nc = -1\\nD = b**2 - 4*a*c\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\nroot1, root2'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\na = 3\\nb = 2\\nc = -1\\nD = b**2 - 4*a*c\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\n(root1, root2)'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\na = 3\\nb = 2\\nc = -1\\nD = b**2 - 4*a*c\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\n(root1, root2)'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\na = 3\\nb = 2\\nc = -1\\nD = b**2 - 4*a*c\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\n(root1, root2)'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\na = 3\\nb = 2\\nc = -1\\nD = b**2 - 4*a*c\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\n(root1, root2)'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\na = 3\\nb = 2\\nc = -1\\nD = b**2 - 4*a*c\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\n(root1, root2)'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\na = 3\\nb = 2\\nc = -1\\nD = b**2 - 4*a*c\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\n(root1, root2)'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\na = 3\\nb = 2\\nc = -1\\nD = b**2 - 4*a*c\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\n(root1, root2)'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\n\\na = 3\\nb = 2\\nc = -1\\nD = b**2 - 4*a*c\\nroot1 = (-b + np.sqrt(D)) / (2*a)\\nroot2 = (-b - np.sqrt(D)) / (2*a)\\n(root1, root2)'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mTo find the roots of the quadratic function \\(3x^2 + 2x - 1\\), we can use the quadratic formula:\n",
            "\n",
            "\\[\n",
            "x = \\frac{-b \\pm \\sqrt{D}}{2a}\n",
            "\\]\n",
            "\n",
            "where \\(D\\) (the discriminant) is given by \\(D = b^2 - 4ac\\).\n",
            "\n",
            "For the function \\(3x^2 + 2x - 1\\):\n",
            "- \\(a = 3\\)\n",
            "- \\(b = 2\\)\n",
            "- \\(c = -1\\)\n",
            "\n",
            "Calculating the discriminant:\n",
            "\n",
            "\\[\n",
            "D = 2^2 - 4 \\cdot 3 \\cdot (-1) = 4 + 12 = 16\n",
            "\\]\n",
            "\n",
            "Now, we can find the roots:\n",
            "\n",
            "\\[\n",
            "x_1 = \\frac{-2 + \\sqrt{16}}{2 \\cdot 3} = \\frac{-2 + 4}{6} = \\frac{2}{6} = \\frac{1}{3}\n",
            "\\]\n",
            "\n",
            "\\[\n",
            "x_2 = \\frac{-2 - \\sqrt{16}}{2 \\cdot 3} = \\frac{-2 - 4}{6} = \\frac{-6}{6} = -1\n",
            "\\]\n",
            "\n",
            "Thus, the roots of the quadratic function \\(3x^2 + 2x - 1\\) are:\n",
            "\n",
            "\\[\n",
            "x_1 = \\frac{1}{3}, \\quad x_2 = -1\n",
            "\\]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "To find the roots of the quadratic function \\(3x^2 + 2x - 1\\), we can use the quadratic formula:\n",
            "\n",
            "\\[\n",
            "x = \\frac{-b \\pm \\sqrt{D}}{2a}\n",
            "\\]\n",
            "\n",
            "where \\(D\\) (the discriminant) is given by \\(D = b^2 - 4ac\\).\n",
            "\n",
            "For the function \\(3x^2 + 2x - 1\\):\n",
            "- \\(a = 3\\)\n",
            "- \\(b = 2\\)\n",
            "- \\(c = -1\\)\n",
            "\n",
            "Calculating the discriminant:\n",
            "\n",
            "\\[\n",
            "D = 2^2 - 4 \\cdot 3 \\cdot (-1) = 4 + 12 = 16\n",
            "\\]\n",
            "\n",
            "Now, we can find the roots:\n",
            "\n",
            "\\[\n",
            "x_1 = \\frac{-2 + \\sqrt{16}}{2 \\cdot 3} = \\frac{-2 + 4}{6} = \\frac{2}{6} = \\frac{1}{3}\n",
            "\\]\n",
            "\n",
            "\\[\n",
            "x_2 = \\frac{-2 - \\sqrt{16}}{2 \\cdot 3} = \\frac{-2 - 4}{6} = \\frac{-6}{6} = -1\n",
            "\\]\n",
            "\n",
            "Thus, the roots of the quadratic function \\(3x^2 + 2x - 1\\) are:\n",
            "\n",
            "\\[\n",
            "x_1 = \\frac{1}{3}, \\quad x_2 = -1\n",
            "\\]\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "python_tool = PythonREPLTool()\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=[python_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,  # modern tool calling\n",
        "    verbose=True,\n",
        "    max_iterations=10,\n",
        "    early_stopping_method=\"generate\"\n",
        ")\n",
        "result = agent.invoke(\"Find the roots (zeros) if the quadratic function 3 * x**2 + 2*x -1\")\n",
        "print(result['output'])\n",
        "\n",
        "# agent.invoke(\"Find the roots (zeros) if the quadratic function 3 * x**2 + 2*x -1\")\n",
        "\n",
        "# agent.invoke(\"Calculate the factorial of 10.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Python_REPL` with `{'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mTo find the roots of the quadratic equation \\(3x^2 + 2x - 1 = 0\\), we can use the quadratic formula:\n",
            "\n",
            "\\[\n",
            "x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n",
            "\\]\n",
            "\n",
            "where \\(a = 3\\), \\(b = 2\\), and \\(c = -1\\).\n",
            "\n",
            "1. Calculate the discriminant:\n",
            "   \\[\n",
            "   b^2 - 4ac = 2^2 - 4 \\cdot 3 \\cdot (-1) = 4 + 12 = 16\n",
            "   \\]\n",
            "\n",
            "2. Now apply the quadratic formula:\n",
            "   \\[\n",
            "   x = \\frac{-2 \\pm \\sqrt{16}}{2 \\cdot 3} = \\frac{-2 \\pm 4}{6}\n",
            "   \\]\n",
            "\n",
            "3. This gives us two solutions:\n",
            "   - For the positive root:\n",
            "     \\[\n",
            "     x_1 = \\frac{-2 + 4}{6} = \\frac{2}{6} = \\frac{1}{3}\n",
            "     \\]\n",
            "   - For the negative root:\n",
            "     \\[\n",
            "     x_2 = \\frac{-2 - 4}{6} = \\frac{-6}{6} = -1\n",
            "     \\]\n",
            "\n",
            "Thus, the roots of the equation \\(3x^2 + 2x - 1 = 0\\) are:\n",
            "\n",
            "\\[\n",
            "x = \\frac{1}{3} \\quad \\text{and} \\quad x = -1\n",
            "\\]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "To find the roots of the quadratic equation \\(3x^2 + 2x - 1 = 0\\), we can use the quadratic formula:\n",
            "\n",
            "\\[\n",
            "x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n",
            "\\]\n",
            "\n",
            "where \\(a = 3\\), \\(b = 2\\), and \\(c = -1\\).\n",
            "\n",
            "1. Calculate the discriminant:\n",
            "   \\[\n",
            "   b^2 - 4ac = 2^2 - 4 \\cdot 3 \\cdot (-1) = 4 + 12 = 16\n",
            "   \\]\n",
            "\n",
            "2. Now apply the quadratic formula:\n",
            "   \\[\n",
            "   x = \\frac{-2 \\pm \\sqrt{16}}{2 \\cdot 3} = \\frac{-2 \\pm 4}{6}\n",
            "   \\]\n",
            "\n",
            "3. This gives us two solutions:\n",
            "   - For the positive root:\n",
            "     \\[\n",
            "     x_1 = \\frac{-2 + 4}{6} = \\frac{2}{6} = \\frac{1}{3}\n",
            "     \\]\n",
            "   - For the negative root:\n",
            "     \\[\n",
            "     x_2 = \\frac{-2 - 4}{6} = \\frac{-6}{6} = -1\n",
            "     \\]\n",
            "\n",
            "Thus, the roots of the equation \\(3x^2 + 2x - 1 = 0\\) are:\n",
            "\n",
            "\\[\n",
            "x = \\frac{1}{3} \\quad \\text{and} \\quad x = -1\n",
            "\\]\n",
            "[(AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 104, 'total_tokens': 147, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHV07UbV44qoujzS7ilpZOcV6Qi4', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-23e7-7a53-b8bd-d560052bfea8-0', usage_metadata={'input_tokens': 104, 'output_tokens': 43, 'total_tokens': 147, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), ''), (AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 156, 'total_tokens': 199, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHV1hbcL7bMdLseDe71XQXmbFphy', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-2857-7b60-8954-0dc17cdec57a-0', usage_metadata={'input_tokens': 156, 'output_tokens': 43, 'total_tokens': 199, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), ''), (AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 208, 'total_tokens': 251, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHV2Bs86tPqCYcMJfsijNgUXrGUT', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-2de3-7842-816f-6bfa6fa33534-0', usage_metadata={'input_tokens': 208, 'output_tokens': 43, 'total_tokens': 251, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), ''), (AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 260, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHV4tjOitC3b1YkeMfu40zYD5Aj6', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-32e3-7693-9d85-9cd8cbead528-0', usage_metadata={'input_tokens': 260, 'output_tokens': 43, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), ''), (AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 312, 'total_tokens': 355, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHV6U66w6nd69qrK4bSXy9lE9IP9', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-3b46-7ee1-93ff-cbe5a157d2d1-0', usage_metadata={'input_tokens': 312, 'output_tokens': 43, 'total_tokens': 355, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), ''), (AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 364, 'total_tokens': 407, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHV79U4rkcYhxQSolujTTGuV8H47', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-401e-7ef0-9123-99872109b50c-0', usage_metadata={'input_tokens': 364, 'output_tokens': 43, 'total_tokens': 407, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), ''), (AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 416, 'total_tokens': 459, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHV8hamI3SLCl1MARWeY0zPH5BR0', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-44e7-78d2-a5ec-f147bc019953-0', usage_metadata={'input_tokens': 416, 'output_tokens': 43, 'total_tokens': 459, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), ''), (AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 468, 'total_tokens': 511, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHVAKE3uYD8t7C8Qq57UQIGZVRG1', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-4a22-7790-a1e2-515f578853ec-0', usage_metadata={'input_tokens': 468, 'output_tokens': 43, 'total_tokens': 511, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), ''), (AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 520, 'total_tokens': 563, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHVBS30aq6C258zVllvdxF59OKHr', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-4e40-75d1-b9ac-f34975f38f38-0', usage_metadata={'input_tokens': 520, 'output_tokens': 43, 'total_tokens': 563, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), ''), (AgentActionMessageLog(tool='Python_REPL', tool_input={'query': 'import numpy as np\\ncoefficients = [3, 2, -1]\\nroots = np.roots(coefficients)\\nroots'}, log=\"\\nInvoking: `Python_REPL` with `{'query': 'import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"import numpy as np\\\\ncoefficients = [3, 2, -1]\\\\nroots = np.roots(coefficients)\\\\nroots\"}', 'name': 'Python_REPL'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 572, 'total_tokens': 615, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DCHVDEIuTmv7dCDXShvecn4pJo690', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--019c88ad-548b-7eb3-8fbd-1894f811aaa1-0', usage_metadata={'input_tokens': 572, 'output_tokens': 43, 'total_tokens': 615, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]), '')]\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_exec = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent.agent,           # some versions use agent.agent; if this errors, skip this block\n",
        "    tools=[python_tool],\n",
        "    verbose=True,\n",
        "    max_iterations=10,\n",
        "    early_stopping_method=\"generate\",\n",
        "    return_intermediate_steps=True,\n",
        ")\n",
        "\n",
        "res = agent_exec.invoke({\"input\": \"Find the roots (zeros) of 3*x**2 + 2*x - 1\"})\n",
        "print(res[\"output\"])\n",
        "print(res[\"intermediate_steps\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/ahmedibrahim/Desktop/Mids/projects_2026/langchain-13-min/venvl/bin/python\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venvl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
